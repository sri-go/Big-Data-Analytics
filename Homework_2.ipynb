{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Homework_2.ipynb","provenance":[{"file_id":"1K0hp-Y5R7FHa3AwfAj2tCw3ueXOlJhay","timestamp":1569693765142}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"DKCcZ2_rosJ0","colab_type":"text"},"source":["# CIS 545 - Big Data Analytics - Fall 2019"]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"syxh_fwyTAVU","nbgrader":{"cell_type":"markdown","checksum":"07f80342af7b3f53232fa665711a4f8d","grade":false,"grade_id":"cell-fe1ccb2b0cf04ec5","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["# Homework 2: Querying Linked (LinkedIn) Data\n","\n","# Due October 11, 2019 at 10pm"]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"-kIU5Hyh_ze0","nbgrader":{"cell_type":"markdown","checksum":"66956d89cf4b869a752255872c9acf23","grade":false,"grade_id":"cell-388a39fc469b703f","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["Have you ever wondered about (1) what it takes to be a data scientist or \"data person\", and (2) how social networks and recommender systems work?\n","\n","This homework is focused on (1) working with hierarchical data stored in dataframes, (2) traversing relationships among data, including graph data, (3) understanding a bit about performance.\n","\n","We will focus on questions about data scientists from \"our\" crawl of the LinkedIn dataset, which was also used in the Lecture (module) 2 extended notebook."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"84c0VetBS-Ae","colab":{}},"source":["!pip install pymongo[tls,srv]\n","!pip install swifter\n","!pip install lxml"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0yFCA_BnTDWL","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import json\n","import sqlite3\n","from lxml import etree\n","import urllib\n","import zipfile\n","\n","import time\n","import swifter\n","from pymongo import MongoClient\n","from pymongo.errors import DuplicateKeyError, OperationFailure"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"62VpoB2eU6lz","nbgrader":{"cell_type":"markdown","checksum":"2c1ade1ed098ba7b6d850eebda8d566f","grade":false,"grade_id":"cell-2bb8ffaa9ddfdf13","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["# Step 0: Acquire and load data\n","\n","We need to pull the zipfile with LinkedIn data from Amazon S3 (where it is shared) to your local machine or the Google Colab cloud-hosted machine.  Only when the data is local can we efficiently parse it (and we'll read directly out of a zip file).\n","\n","The zip file contains three files with the same schema.  You can start with the `tiny` instance to test your queries, then go on to `small`.  If you're brave and have a lot of time feel free to use the full file.\n","\n","**We will grade your homework using `small`. Hidden test 0.0 will override your file selection, so as long as you do not change the file selection in a cell that comes after that one, you will be fine.**\n","\n","* `linkedin.json` (3M records)\n","* `linkedin_small.json` (100K records)\n","* `linkedin_tiny.json` (10K records)\n","\n","The cell below will download a 3GB file to your Google Cloud. It may take a while. You do not need to modify the two cells below."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Y5pOCyFCgTtY","colab":{}},"source":["url = 'https://upenn-bigdataanalytics.s3.amazonaws.com/linkedin.zip'\n","filehandle, _ = urllib.request.urlretrieve(url,filename='local.zip')\n","filehandle = 'local.zip'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pi5XAWkehTOJ","colab":{}},"source":["# What's the zip file actually called locally?\n","filehandle"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"641d22e91a3dae8a1ae26cfd88714eea","grade":false,"grade_id":"cell-f81f52c4a3ec94ad","locked":true,"schema_version":3,"solution":false,"task":false},"id":"VY64R_HyosKJ","colab_type":"text"},"source":["![alt text](https://)The cell below creates pointers to the three versions of our dataset. To switch between them, simply change the `file` variable in the cell after the cell below."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JwpR-SU_gzMC","colab":{}},"source":["def fetch_file(fname):\n","    zip_file_object = zipfile.ZipFile(filehandle, 'r')\n","    for file in zip_file_object.namelist():\n","        file = zip_file_object.open(file)\n","        if file.name == fname: return file\n","    return None\n","    \n","linkedin_tiny = fetch_file('linkedin_tiny.json')\n","linkedin_small = fetch_file('linkedin_small.json')\n","linkedin_huge = fetch_file('linkedin.json')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"4ocD2cu9cyxP","nbgrader":{"cell_type":"code","checksum":"11dfe943eabcda794c7cbeb159221392","grade":true,"grade_id":"0-0-test","locked":true,"points":0,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Hidden Test 0.0 - please do not modify or delete this cell!\n","\n","# Set the input file to process\n","file = linkedin_small"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"ud1c3IAbhszs","nbgrader":{"cell_type":"markdown","checksum":"468120adc95b35087ae865792ad51f00","grade":false,"grade_id":"cell-63e729eee9ebf28b","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["## Step 0.1:  Store data in dataframes\n","\n","In the cell below, adapt the data loading code from the [in-class notebook](https://colab.research.google.com/drive/1V-QGYHI3YdLVv3sjnfQn7xmy6xEdjJnm).  You will need the function that extracts relations from JSON files and the function that converts relations to dataframes. Read in a maximum of 20000 people. Put the code that reads a line of the file, extracts the relations, removes the interval field, and stores the field information with a try statement, just in case. In the error case, just use a `pass` command to move on. At the end of the next cell, you should have nine dataframes with the following names:\n","\n","1. `people_df`\n","2. `names_df`\n","3. `education_df`\n","4. `groups_df`\n","5. `skills_df`\n","6. `experience_df`\n","7. `honors_df`\n","8. `also_view_df`\n","9. `events_df`"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"08Fnhejfhr1P","nbgrader":{"cell_type":"code","checksum":"9b46968eac5d4f8299c77f32769abe04","grade":false,"grade_id":"0-1-ans","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{}},"source":["# TODO: Adapt the data loading code from class\n","START = 0\n","LIMIT = 20000\n","\n","def get_df(rel):\n","    ret = pd.DataFrame(rel).fillna('')\n","    for k in ret.keys():\n","        ret[k] = ret[k].astype(str)\n","    return ret\n","\n","def extract_relation(rel, name):\n","    '''\n","    Pull out a nested list that has a key, and return it as a list\n","    of dictionaries suitable for treating as a relation / dataframe\n","    '''\n","    # We'll return a list\n","    ret  = []\n","    if name in rel:\n","        ret2 = rel.pop(name)\n","        try:\n","            # Try to parse the string as a dictionary\n","            ret2 = json.loads(ret2.replace('\\'','\\\"'))\n","        except:\n","            # If we get an error in parsing, we'll leave as a string\n","            pass\n","        \n","        # If it's a dictionary, add it to our return results after\n","        # adding a key to the parent\n","        if isinstance(ret2, dict):\n","            item = ret2\n","            item['person'] = rel['_id']\n","            ret.append(item)\n","        else:\n","            # If it's a list, iterate over each item\n","            index = 0\n","            for r in ret2:\n","                item = r\n","                if not isinstance(item, dict):\n","                    item = {'person': rel['_id'], 'value': item}\n","                else:\n","                    item['person'] = rel['_id']\n","                    \n","                # A fix to a typo in the data\n","                if 'affilition' in item:\n","                    item['affiliation'] = item.pop('affilition')\n","                    \n","                item['pos'] = index\n","                index = index + 1\n","                ret.append(item)\n","    return ret\n","\n","#Parsing through the data\n","names = []\n","people = []\n","groups = []\n","education = []\n","skills = []\n","experience = []\n","honors = []\n","also_view = []\n","events = []\n","\n","lines = []\n","i = 1\n","for line in file:\n","    if i > START + LIMIT:\n","        break\n","    elif i >= START:\n","        person = json.loads(line)\n","\n","        # By inspection, all of these are nested dictionary or list content\n","        nam = extract_relation(person, 'name')\n","        edu = extract_relation(person, 'education')\n","        grp = extract_relation(person, 'group')\n","        skl = extract_relation(person, 'skills')\n","        exp  = extract_relation(person, 'experience')\n","        hon = extract_relation(person, 'honors')\n","        als = extract_relation(person, 'also_view')\n","        eve = extract_relation(person, 'events')\n","        \n","        # This doesn't seem relevant and it's the only\n","        # non-string field that's sometimes null\n","        if 'interval' in person:\n","            person.pop('interval')\n","        \n","        lines.append(person)\n","        names = names + nam\n","        education = education + edu\n","        groups  = groups + grp\n","        skills = skills + skl\n","        experience = experience + exp\n","        honors = honors + hon\n","        also_view = also_view + als\n","        events = events + eve\n","        \n","    i = i + 1\n","\n","people_df = get_df(pd.DataFrame(lines))\n","names_df = get_df(pd.DataFrame(names))\n","education_df = get_df(pd.DataFrame(education))\n","groups_df = get_df(pd.DataFrame(groups))\n","skills_df = get_df(pd.DataFrame(skills))\n","experience_df = get_df(pd.DataFrame(experience))\n","honors_df = get_df(pd.DataFrame(honors))\n","also_view_df = get_df(pd.DataFrame(also_view))\n","events_df = get_df(pd.DataFrame(events))\n","# YOUR CODE HERE\n","#raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"ufXTMBMiSoPw","nbgrader":{"cell_type":"code","checksum":"d777f998083497aa09c5865d9204eff7","grade":true,"grade_id":"0-1-san","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Sanity Check 0.1 - please do not modify or delete this cell!\n","display(skills_df)\n","display(experience_df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"y6f7BRIfTFKx","nbgrader":{"cell_type":"code","checksum":"78b6dc108b874641b07739eef9ef896d","grade":true,"grade_id":"0-1-1-test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Hidden Test 0.1.1 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"8vEobQewTfGT","nbgrader":{"cell_type":"code","checksum":"662cb96b4661930faefdd11957fb46a8","grade":true,"grade_id":"0-1-2-test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Hidden Test 0.1.2 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"cXeSZ94XTmZ2","nbgrader":{"cell_type":"code","checksum":"25a05a576ed9001b90b8f5d40d06cbe2","grade":true,"grade_id":"0-1-3-test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Hidden Test 0.1.3 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"2uovhjepA2cE","nbgrader":{"cell_type":"markdown","checksum":"acbffcab652282ef674d69b4aede35ee","grade":false,"grade_id":"cell-a7b3effa108ede81","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["## Step 0.2: Convert to SQL\n","\n","Next save the data to SQLite...  Again, using the same approach as in the sample notebook."]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"OMEndMrM282B","nbgrader":{"cell_type":"code","checksum":"22f773d4d8bbce7949196b5e993953e9","grade":false,"grade_id":"0-2-ans","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{}},"source":["conn = sqlite3.connect('linkedin.db')\n","\n","people_df.to_sql('people', conn, if_exists='replace', index=False)\n","names_df.to_sql('names', conn, if_exists='replace', index=False)\n","education_df.to_sql('education', conn, if_exists='replace', index=False)\n","groups_df.to_sql('groups', conn, if_exists='replace', index=False)\n","skills_df.to_sql('skills', conn, if_exists='replace', index=False)\n","experience_df.to_sql('experience', conn, if_exists='replace', index=False)\n","honors_df.to_sql('honors', conn, if_exists='replace', index=False)\n","also_view_df.to_sql('also_view', conn, if_exists='replace', index=False)\n","events_df.to_sql('events', conn, if_exists='replace', index=False)\n","\n","# YOUR CODE HERE\n","#raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"nWX716u93MLx","nbgrader":{"cell_type":"code","checksum":"21c423cb12953ae8180755b8dedfb787","grade":true,"grade_id":"0-2-1-san","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Sanity Check 0.2.1 - please do not modify or delete this cell!\n","\n","people_df.describe()\n","names_df.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"fD1WW-4qiHP8","nbgrader":{"cell_type":"code","checksum":"d98de5be163a08b9ae53b904ca7e514b","grade":true,"grade_id":"0-2-2-san","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Sanity Check 0.2.2 - please do not modify or delete this cell!\n","\n","skills_df.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"N7AO3Um0iHYE","nbgrader":{"cell_type":"code","checksum":"1e77e70a7887a6508367b725680c5db0","grade":true,"grade_id":"0-2-3-san","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Sanity Check 0.2.3 - please do not modify or delete this cell!\n","\n","experience_df.describe()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"02e5b3fb9eafa5a8b62a563ed7c52ded","grade":false,"grade_id":"cell-27e9476d548c1f91","locked":true,"schema_version":3,"solution":false,"task":false},"id":"vO7so7yeosK3","colab_type":"text"},"source":["# Step 1: What is a data scientist?\n","\n","In this homework, we will use LinkedIn to analyze what it means to be a data scientist (as of a few years ago)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"HfsP26IsUe1A","nbgrader":{"cell_type":"markdown","checksum":"53c1979a54ca8c16fd8347ed1ec376dc","grade":false,"grade_id":"cell-2933239c97f3b64b","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["## Step 1.1: What are common skills for data scientists?\n","\n","Our first question is:  for anyone who's job revolves around data (database administrators, data curators, data engineers, data scientists), *what are the most common skills*?"]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"a6496060fced0feb46fac9e7436ac3d0","grade":false,"grade_id":"cell-d865dc7de26f1fd6","locked":true,"schema_version":3,"solution":false,"task":false},"id":"bTMd2MrDosK5","colab_type":"text"},"source":["### Step 1.1.1: Collect skills (Pandas)\n","\n","Complete the `collect_skills` function below. This and the other functions in this homework allow us to evaluate the correctness of your queries even if your data do not match ours. The function should:\n","\n","1. Using `experience_df`, find all people with a position containing \"data\" in the title. Remember upper versus lower case.\n","2. Using `skills_df`, find all people with \"data science\" as a skill. Again, remember to account for case.\n","3. For all of the unique people found in steps 1 and 2, find the rest of their skills\n","4. Return a dataframe of the top 15 skills, by frequency  (see pandas.DataFrame.sort_values).  The columns should be called `skill` (the name of the skill) and `scientists` (the count of the number of data scientists with this skill)."]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"fr0Yn1o3Ui7V","nbgrader":{"cell_type":"code","checksum":"da69dce7c3db681dc18d0e3768cc7528","grade":false,"grade_id":"1-1-1-ans","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{}},"source":["# TODO: Find the top 15 skills for data scientists (Pandas)\n","def collect_skills(experience_df, people_df, skills_df):\n","    #find all people with data in name:\n","    experience_df['title'] = experience_df['title'].apply(lambda x: x.lower())\n","    people_with_data = experience_df[experience_df['title'].str.contains(r'.*(data.*)')]['person']\n","    display(people_with_data)\n","\n","    skills_df['value'] = skills_df['value'].apply(lambda x: x.lower())\n","    people_with_data_science = skills_df[skills_df['value'].str.contains(r'.*(data science.*)')]['person']\n","    display(people_with_data_science)\n","\n","    unique_people = pd.concat([people_with_data, people_with_data_science]).to_frame()\n","    #unique_people = people_with_data.merge(people_with_data_science, how = 'outer', left_on = 'person', right_on = 'person').to_frame()['person'].drop_duplicates()\n","    #display(unique_people)\n","\n","    new_skills = unique_people.merge(skills_df, how = 'inner', left_on = 'person', right_on = 'person').rename(columns={'value':'skill'}).drop_duplicates()\n","    display(new_skills)\n","    \n","    #top_skills = new_skills.groupby(['value'], as_index = False).count()\n","    top_skills = new_skills.groupby('skill').skill.count().nlargest(15).to_frame('scientists').reset_index()\n","    display(top_skills)\n","\n","    return top_skills\n","    # YOUR CODE HERE\n","    #raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"F_m25KVi7ShY","nbgrader":{"cell_type":"code","checksum":"922dc7409fb35908681e1b7d121ebcad","grade":true,"grade_id":"1-1-1-san","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Sanity Check 1.1.1 - please do not modify or delete this cell!\n","top_skills_df = collect_skills(experience_df, people_df, skills_df)\n","display(top_skills_df)\n","\n","if \"skill\" not in top_skills_df:\n","    raise AssertionError(\"skill column not defined\")\n","if \"scientists\" not in top_skills_df:\n","    raise AssertionError(\"scientists column not defined\")\n","if len(top_skills_df) != 15:\n","    raise AssertionError(\"dataframe does not have top 15\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"nODdmq1T8SIK","nbgrader":{"cell_type":"code","checksum":"722d156a1c8c5a23ac56684d129d09d6","grade":true,"grade_id":"1-1-1-1-test","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Hidden Test 1.1.1.1 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"c51f4bfa2f2bb22007d343112b3b3850","grade":true,"grade_id":"1-1-1-2-test","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"id":"RfMFNzZCosLO","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.1.1.2 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"bb357a85ce3589003897d6cd6ce0cb84","grade":true,"grade_id":"1-1-1-3-test","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"id":"_CUj3OqLosLT","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.1.1.3 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"lPznbHEzBY1c","nbgrader":{"cell_type":"markdown","checksum":"7fb1000c692e052541c5d9eaacfee853","grade":false,"grade_id":"cell-cf04468b3ecce3ec","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### Step 1.1.2: Top skills (SQL)\n","\n","Compute the same table as in 1.1.1 using SQL. Store it as `top_skills_sql` but otherwise matching the schema and other properties. Be sure to also save the data to SQLLite in a table called `top_skills`, as we will be testing to see if this table exists."]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"4r8kF8Uc3daC","nbgrader":{"cell_type":"code","checksum":"1d7d38699534609e77618430bc530276","grade":false,"grade_id":"1-1-2-ans","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{}},"source":["# TODO: Find the top 15 skills for data scientists (SQL)\n","\n","# YOUR CODE HERE\n","conn.execute('''DROP VIEW IF EXISTS experience_sql''')\n","conn.execute('''CREATE VIEW experience_sql AS\n","             SELECT DISTINCT person\n","             FROM experience \n","             WHERE LOWER(title) like '%data%'\n","             ''')\n","\n","conn.execute('''DROP VIEW IF EXISTS new_skills_sql''')\n","conn.execute('''CREATE VIEW new_skills_sql AS\n","             SELECT DISTINCT person\n","             FROM skills \n","             WHERE LOWER(value) LIKE '%data science%' \n","             ''')\n","#unique_people = people_with_data.merge(people_with_data_science, how = 'outer', left_on = 'person', right_on = 'person')['person'].to_frame().drop_duplicates()\n","\n","conn.execute('''DROP VIEW IF EXISTS newer_skills_sql''')\n","conn.execute('''CREATE VIEW newer_skills_sql AS\n","             SELECT DISTINCT e.person\n","             FROM experience_sql e\n","             LEFT JOIN new_skills_sql s USING(person)\n","             UNION ALL\n","             SELECT DISTINCT e.person\n","             FROM new_skills_sql s\n","             LEFT JOIN experience_sql e USING(person)\n","             ''')\n","\n","#new_skills = unique_people.merge(skills_df, how = 'left', left_on = 'person', right_on = 'person').dropna().rename(columns={'value':'skills'})\n","\n","#top_skills = new_skills.groupby('skills').skills.count().nlargest(15).to_frame('scientists').reset_index().rename(columns={\"skills\": \"skill\"})\n","conn.execute('''DROP VIEW IF EXISTS top_skills''')\n","conn.execute('''CREATE VIEW top_skills AS\n","             SELECT value as skill, COUNT(value) as scientists\n","             FROM newer_skills_sql\n","             INNER JOIN skills ON skills.person = newer_skills_sql.person\n","             GROUP BY value\n","             ORDER BY COUNT(value) DESC\n","             LIMIT 15\n","             ''')\n","\n","top_skills_sql = pd.read_sql_query('''\n","                              SELECT * FROM top_skills\n","                              ''', conn)\n","\n","display(top_skills)\n","#display(unique_df)\n","#display(skills_df)\n","#display(experience_df)\n","#raise NotImplementedError()\n","#display(top_skills_sql)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"Sy6sTN_VBdsQ","nbgrader":{"cell_type":"code","checksum":"33802b40e5377120929b041de0732e15","grade":true,"grade_id":"1-1-2-san","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["#CIS 545 Sanity Check 1.1.2 - please do not modify or delete this cell!\n","\n","\n","\n","if \"skill\" not in top_skills_sql:\n","    raise AssertionError(\"skill column not defined\")\n","if \"scientists\" not in top_skills_sql:\n","    raise AssertionError(\"scientists column not defined\")\n","if len(top_skills_df) < 1:\n","    raise AssertionError(\"dataframe has no results\")  \n","if len(top_skills_sql.merge(top_skills_df)) != len(top_skills_sql):\n","    raise AssertionError(\"Pandas and SQL versions are not of the same length\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"qwgWz03YBdze","nbgrader":{"cell_type":"code","checksum":"2904b0c7d73eaa42d9716e64e76277d3","grade":true,"grade_id":"1-1-2-test","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Hidden Test 1.1.2 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"Mr7NCZbeUjdx","nbgrader":{"cell_type":"markdown","checksum":"28ace417561ffc2eee48204e31170391","grade":false,"grade_id":"cell-36c63a97e893dd5f","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["## Step 1.2: What are common titles for those with data science skills?\n","\n","Complete the `collect_titles` function below that aggregates the most recent titles of people with data science skills. This function should use the given dataframes as input and return a two column dataframe: one column called `title` and the other called `count`. You should only consider people who have at least `min_skills` of the top skills for a data scientist. You should also only keep those titles that appear at least `min_count` times.\n","\n","For extra practice, you can also do this in SQL, although we are not grading that."]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"kyNL9Y_0UmgI","nbgrader":{"cell_type":"code","checksum":"18899df92c34a290a94b7c73ecff3428","grade":false,"grade_id":"1-2-ans","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{}},"source":["# TODO: Find the common titles (Pandas)\n","def collect_titles(top_skills_df, skills_df, people_df, experience_df, min_skills, min_count):\n","    # YOUR CODE HERE\n","\n","    #.skills.count().nlargest(15).to_frame('scientists').reset_index().rename(columns={\"skills\": \"skill\"})\n","    #find all the people_ids associated with the top skills\n","    new_skills = skills_df.merge(top_skills_df, how = 'inner', left_on = 'value', right_on = 'skill')\n","    new_skills = new_skills.drop(columns=['scientists', 'skill','pos'])\n","    display(new_skills)\n","\n","    #filter these people to see that they have 6+ skills\n","    people_with_min_skills = new_skills.groupby(['person']).count().sort_values(by = 'value').reset_index()\n","    #display(people_with_min_skills)\n","    people_with_min_skills = people_with_min_skills[people_with_min_skills['value'] >= min_skills]\n","    display(people_with_min_skills)\n","\n","    #append to final dataframe if the title appears more min_count times (2x)\n","    almost_final_dataframe = experience_df.merge(people_with_min_skills, how = 'inner', left_on = 'person', right_on = 'person')\n","    display(almost_final_dataframe)\n","    almost_final_dataframe = almost_final_dataframe[(almost_final_dataframe['end'] == 'Present') | (almost_final_dataframe['pos'] == 0)]\n","    display(almost_final_dataframe)\n","\n","    final_dataframe = almost_final_dataframe.groupby(['title']).title.count().to_frame('count').sort_values(by = 'count', ascending = False).reset_index()\n","    display(final_dataframe)\n","    final_dataframe = final_dataframe[final_dataframe['count'] >= min_count]\n","    display(final_dataframe)\n","\n","    return final_dataframe\n","    #raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"05-3-KKnCDGO","nbgrader":{"cell_type":"code","checksum":"107fe92efffb369487808f3317868c04","grade":true,"grade_id":"1-2-san","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["\n","# CIS 545 Sanity Check 1.2 - please do not modify or delete this cell!\n","\n","ds_titles_df = collect_titles(top_skills_df, skills_df, people_df, experience_df, 6, 2)\n","display(ds_titles_df)\n","\n","'''if \"title\" not in ds_titles_df:\n","    raise AssertionError(\"title column not defined\")\n","if \"count\" not in ds_titles_df:\n","    raise AssertionError(\"count column not defined\")\n","if len(ds_titles_df) < 1:\n","    raise AssertionError(\"dataframe has no results\")'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"XtizbGmOCEOv","nbgrader":{"cell_type":"code","checksum":"a0a604676fa24e25408bde594dc72a3e","grade":true,"grade_id":"1-2-1-test","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Hidden Test 1.2.1 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"e9d11a502486a3dd11d904a5b81f8791","grade":true,"grade_id":"1-2-2-test","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"id":"Y9OwGQPAosLr","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.2.2 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"19a7b52f4ccce1fd118fe8d2727c1014","grade":true,"grade_id":"1-2-3-test","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"id":"EhcOoMqfosLv","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.2.3 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"YBgiL8fVUnGt","nbgrader":{"cell_type":"markdown","checksum":"18f857221c00c8a5f2c356dfae706501","grade":false,"grade_id":"cell-cfd32357d45804b8","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["## Step 1.3: Who employs \"data people\" based on title?\n","\n","Now let's find the list of companies that have employed people with the above titles, ranked by number of employees who have had these titles."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"37434e39b4fc4ce02667b8609774828d","grade":false,"grade_id":"cell-afdd83d23848f31e","locked":true,"schema_version":3,"solution":false,"task":false},"id":"-zUk384vosL2","colab_type":"text"},"source":["### Step 1.3.1: Data employers\n","\n","Complete the `collect_employers` function below that aggregates the employers with positions corresponding to the most recent titles of people with data science skills. This function should use the given dataframes as input and return a two column dataframe: one column called `org` and the other called `people`. Show the names of companies (in field `org`) with at least `min_count` employees who are \"data people\" (include that count in the `people` column). Order the dataframe by the count of data people in the company in descending order."]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"ScdYcC1gUsTN","nbgrader":{"cell_type":"code","checksum":"0ea84c78c46e5baa28e3c904fef93706","grade":false,"grade_id":"1-3-1-ans","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{}},"source":["# TODO: Find the data employers\n","\n","def collect_employers(experience_df, ds_titles_df, min_count):\n","    # YOUR CODE HERE\n","    new_dataframe = experience_df.merge(ds_titles_df, how = 'inner', left_on = 'title', right_on = 'title').drop(columns = {'desc', 'end', 'person', 'pos', 'start', 'title'})\n","    display(new_dataframe)\n","\n","    grouped_dataset = new_dataframe.groupby(['org']).org.count().to_frame('count').sort_values(by='count', ascending=False).reset_index()\n","    grouped_dataset = grouped_dataset[grouped_dataset['count'] >= min_count].rename(columns = {'count':'people'})\n","    display(grouped_dataset)\n","    \n","    return grouped_dataset\n","\n","    #.title.count().to_frame('count').sort_values(by = 'count', ascending = False).reset_index()\n","\n","    #new_dataframe = new_dataframe[new_dataframe['title'] >= min_count]\n","    #raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"JBeTnIkCiN1P","nbgrader":{"cell_type":"code","checksum":"c0e0f45f4b2658f5efbeb30475fe5c3b","grade":true,"grade_id":"1-3-1-san","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Sanity Check 1.3.1 - please do not modify or delete this cell!\n","\n","employers_df = collect_employers(experience_df, ds_titles_df, 5)\n","display(employers_df)\n","\n","if \"IBM\" not in employers_df['org'].tolist():\n","    raise AssertionError(\"Missing IBM\")\n","    \n","if employers_df['people'].min() < 4:\n","    raise AssertionError(\"Not filtering properly\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"y2_ugwWJiN1U","nbgrader":{"cell_type":"code","checksum":"bacb1ab825cc3fd2ae46426e96b0d8ef","grade":true,"grade_id":"1-3-1-1-test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Hidden Test 1.3.1.1 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"9fbe5ef1dacb6ad75e55250eb717b280","grade":true,"grade_id":"1-3-1-2-test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"tp8tGtOMosMA","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.3.1.2 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"PJVOmhT5J-9f","nbgrader":{"cell_type":"markdown","checksum":"d5e41492d9f990ad61601e075fbaa3a0","grade":false,"grade_id":"cell-b4c4f88eb4655f3c","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### Step 1.3.2:  Their employees\n","\n","Complete the `collect_employees` function below that aggregates the employees of employers with positions corresponding to the most recent titles of people with data science skills. In other words, who are the employees of the data employers you found before and what are their titles? This function should use the given dataframes as input and return the `org`, `family_name`, `given_name`, and `title` of each person."]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"uerRWgAiINiT","nbgrader":{"cell_type":"code","checksum":"9d0873b08744d8a45699686980f65576","grade":false,"grade_id":"1-3-2-ans","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{}},"source":["# TODO: Find the employees of the data employers\n","def collect_employees(people_df, experience_df, employers_df, names_df,ds_titles_df):\n","\n","  #find all titles within employers that has ds_titles_df\n","  new_dataframe = experience_df.merge(ds_titles_df, how = 'inner', left_on = 'title', right_on = 'title')\n","  #display(new_dataframe)\n","\n","  #finding all matching employers from new datafram\n","  newest_datframe = new_dataframe.merge(employers_df, how = 'inner', left_on = 'org', right_on = 'org').drop(columns ={'desc', 'end', 'pos', 'count', 'people'})\n","  display(newest_datframe)\n","\n","  final_dataframe = newest_datframe.merge(names_df, how = 'inner', left_on = 'person', right_on = 'person')[['org','family_name','given_name','title']]\n","  display(final_dataframe)\n","# YOUR CODE HERE\n","#raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"iqRKWa2bibAV","nbgrader":{"cell_type":"code","checksum":"ba086b7b19eb9b2735a3b203580a15d3","grade":true,"grade_id":"1-3-2-san","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["\n","# CIS 545 Sanity Check 1.3.2 - please do not modify or delete this cell!\n","\n","title_people_df = collect_employees(people_df, experience_df, employers_df, names_df, ds_titles_df)\n","display(title_people_df)\n","\n","'''if len(title_people_df.columns) != 4:\n","    raise AssertionError('Wrong number of columns. Check schema again')'''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"PAi09aElibAX","nbgrader":{"cell_type":"code","checksum":"c98013b40f7cdeeff67634f26e7fb62a","grade":true,"grade_id":"1-3-2-1-test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Hidden Test 1.3.2.1 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"d0ca6d57744317edbdf4cef724c15040","grade":true,"grade_id":"1-3-2-2-test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"gkmu9HxaosMM","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.3.2.2 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"c59891aa827aab890a14b62ea15f182d","grade":true,"grade_id":"1-3-2-3-test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"gzxseHgXosMQ","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.3.2.3 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"5XtTFMLsUtYz","nbgrader":{"cell_type":"markdown","checksum":"ba3e867f01f31af6c5b0eb9d104754ba","grade":false,"grade_id":"cell-f5111a385c06e950","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["## Step 1.4: Find peers\n","\n","In many common social graph settings, we can make recommendations to people based on their similarity with other people. In this case, we define similarity in terms of the number of identical skills.\n","\n","Suppose A and B have similar skills: A -> X1 and B -> X1, A -> X2 and B -> X2, etc. up to A -> Xk and B -> Xk.\n","\n","Then given that A and B have similar skills, we might recommend A's employer to B, and vice versa."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"8f4b1bc2d2e59ecef127ac201e9c6046","grade":false,"grade_id":"cell-8a708107d57cde48","locked":true,"schema_version":3,"solution":false,"task":false},"id":"-3kGzYgGosMX","colab_type":"text"},"source":["### Step 1.4.0: Making the problem tractable in Pandas\n","\n","Let's consider only the first 100 people in `people_df`.\n","\n","Find, out of this set, the pairs of people with the most shared/common skills, and return the closest 20 pairs in descending order.  We'll then use this to make a *recommendation* for a potential employer and position to each person."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"7367e94e64fc7ddbb08f6c599a740f2f","grade":false,"grade_id":"cell-69673139d1016aa4","locked":true,"schema_version":3,"solution":false,"task":false},"id":"L8Dtg1kfosMZ","colab_type":"text"},"source":["### Step 1.4.1: Compute the top pairs of peers\n","\n","Complete the `collect_peers` function below that finds the top `num` pairs of peers. In other words, compare each person with each *other* person, counting the total set of skills in common. This function should use the given dataframes and `num` as input and return a three column dataframe: `person_1`, `person_2`, and `common_skills`. The first two columns should be person IDs and the last column should be the number of skills that this pair of people shares.\n","\n","Hint: Doing this requires a *Cartesian product*, i.e., every ID paired with every other ID.  Think about how to create a dataframe just with people IDs, then add a field to this dataframe that will let us combine every record with every record."]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"3WGjZh3PUzLw","nbgrader":{"cell_type":"code","checksum":"22181eb8602d0b2a401709ac5df73b69","grade":false,"grade_id":"1-4-1-ans","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{}},"source":["# TODO: Finish the collect_peers function\n","\n","people_df_subset = people_df.head(100)\n","\n","def collect_peers(people_df_subset, skills_df, num):\n","    people_with_skills = people_df_subset.merge(skills_df, how='inner', left_on = '_id', right_on = 'person')\n","\n","    #display(people_with_skills)\n","    subset_of_skills = people_with_skills.merge(people_with_skills, how = 'inner', left_on = 'value', right_on = 'value').rename(columns={ '_id_x':'person_1', '_id_y':'person_2'})\n","    subset_of_skills = subset_of_skills[subset_of_skills['person_1'] != subset_of_skills['person_2']]\n","    display(subset_of_skills)\n","\n","    final_dataframe = subset_of_skills[['person_1', 'person_2', 'value']].groupby(['person_1', 'person_2'])\\\n","                      .value.count().nlargest(20).to_frame('count').sort_values(by='count', ascending=False).rename(columns={ 'count':'common_skills'}).reset_index()\n","\n","    return final_dataframe\n","    # YOUR CODE HERE\n","    #raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"132367adc67515e7bbb972882f47d34a","grade":true,"grade_id":"1-4-1-san","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"id":"R068G-XjosMd","colab_type":"code","colab":{}},"source":["# CIS 545 Sanity Check 1.4.1 - please do not modify or delete this cell!\n","\n","recs_df = collect_peers(people_df_subset, skills_df, 20)\n","display(recs_df)\n","\n","if \"person_1\" not in recs_df:\n","    raise AssertionError(\"person_1 column not defined\")\n","if \"person_2\" not in recs_df:\n","    raise AssertionError(\"person_2 column not defined\")\n","if \"common_skills\" not in recs_df:\n","    raise AssertionError(\"common_skills column not defined\")\n","if(len(recs_df) != 20):\n","    raise AssertionError('Wrong number of rows in recs_df')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"3a9fa0d1c13c0657225931e7fd85782e","grade":true,"grade_id":"1-4-1-1-test","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"id":"NWt_MrLeosMh","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.4.1.1 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"d16b0911283d768a511292437657048c","grade":true,"grade_id":"1-4-1-2-test","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"id":"EfC8vYljosMl","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.4.1.2 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"5kLiGE3FW4Qn","nbgrader":{"cell_type":"markdown","checksum":"46c2c6336fe8a03f456285dad70c4857","grade":false,"grade_id":"cell-970437a70996b9ab","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["### Step 1.4.2: Get the last jobs\n","\n","Complete the `last_job` function below that takes `experience_df` as input and returns the `person`, `title`, and `org` corresponding to each person's **last** (most recent) employment experience (three column dataframe)."]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"T4bn_WlMjX_u","nbgrader":{"cell_type":"code","checksum":"2e4f3086feae300b07ce6d13394eb74a","grade":false,"grade_id":"1-4-2-ans","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{}},"source":["# TODO: Complete the last_job function\n","\n","def last_job(experience_df):\n","    # YOUR CODE HERE\n","    final_dataframe = experience_df[['person', 'title','pos','org']]\n","    #display(final_dataframe)\n","    final_dataframe = final_dataframe[final_dataframe['pos'] == '0']\n","    #display(final_dataframe)\n","    final_dataframe = final_dataframe[['person', 'title', 'org']]\n","    return final_dataframe\n","    #raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"Uiebdr3VafNT","nbgrader":{"cell_type":"code","checksum":"13912defc16b2da80ca2f30841fbb11b","grade":true,"grade_id":"1-4-2-san","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Sanity Check 1.4.2 - please do not modify or delete this cell!\n","\n","last_job_df = last_job(experience_df)\n","display(last_job_df)\n","\n","if(len(last_job_df.columns) != 3):\n","    raise AssertionError('Wrong number of columns in last_job_df')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"7b2279daacf916953ca84ca27723451a","grade":true,"grade_id":"1-4-2-1-test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"iiSJFNAXosM9","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.4.2.1 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"779b957aaa5868c4c4db44d9d79f7fc6","grade":true,"grade_id":"1-4-2-2-test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"id":"Nw75oq0kosNB","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.4.2.2 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"sJHqsJuxXgNZ","nbgrader":{"cell_type":"code","checksum":"0e7662537271f7d7871b8ed03b0a1930","grade":true,"grade_id":"1-4-2-3-test","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Hidden Test 1.4.2.3 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"a2c39e53cf9abe5b968de4a2cb5fce46","grade":false,"grade_id":"cell-989cf4565f3bbf70","locked":true,"schema_version":3,"solution":false,"task":false},"id":"vVLNWEgCosNG","colab_type":"text"},"source":["### Step 1.4.3: Recommend jobs\n","\n","Complete the `recommend_jobs` function below that takes `recs_df`, `names_df`, and `last_job_df` as input and returns for each `person_1`, `person_2`'s most recent `title` and `org`."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"cell_type":"code","checksum":"069634c2a67cc1fdd40c8d08f1d504ef","grade":false,"grade_id":"1-4-3-ans","locked":false,"schema_version":3,"solution":true,"task":false},"id":"qzyy5e2TosNH","colab_type":"code","colab":{}},"source":["# TODO: Complete the recommend_jobs function\n","\n","def recommend_jobs(recs_df, names_df, last_job_df):\n","    # YOUR CODE HERE\n","    final_person1_dataframe = recs_df.merge(last_job_df, how = 'inner', left_on = 'person_1', right_on = 'person')\n","    #display(final_person1_dataframe)\n","\n","    final_person_2_dataframe = recs_df.merge(last_job_df, how = 'inner', left_on = 'person_2', right_on = 'person')\n","    #display(final_person_2_dataframe)\n","    \n","    final_dataframe = pd.concat([final_person1_dataframe, final_person_2_dataframe], ignore_index=True)\n","    display(final_dataframe)\n","\n","    final_dataframe = final_dataframe.merge(names_df, how = 'inner', left_on = 'person', right_on = 'person')[['family_name', 'given_name', 'org', 'title', 'person_1','person_2', 'common_skills']]\n","    #final_dataframe = final_dataframe.rename(columns={'_id_x':'person_1', '_id_y':'person_2'})\n","    final_dataframe = final_dataframe[final_dataframe['person_1'] != final_dataframe['person_2']]\n","    \n","    #display(final_dataframe)\n","    return final_dataframe\n","    #raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"fa31fa63ac3d81a94a7e0ee7f0f44bcd","grade":true,"grade_id":"1-4-3-san","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"id":"cAUbFfPKosNJ","colab_type":"code","colab":{}},"source":["# CIS 545 Sanity Check 1.4.3 - please do not modify or delete this cell!\n","\n","recommended_df = recommend_jobs(recs_df, names_df, last_job_df)\n","display(recommended_df)\n","\n","if \"family_name\" not in recommended_df:\n","    raise AssertionError(\"person_1 column not defined\")\n","if \"given_name\" not in recommended_df:\n","    raise AssertionError(\"person_2 column not defined\")\n","if \"person_2\" not in recommended_df:\n","    raise AssertionError(\"common_skills column not defined\")\n","if \"org\" not in recommended_df:\n","    raise AssertionError(\"common_skills column not defined\")\n","if \"title\" not in recommended_df:\n","    raise AssertionError(\"common_skills column not defined\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"code","checksum":"b781d85036f5b77c767632de59734bd4","grade":true,"grade_id":"1-4-3-test","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"id":"UtdAav6IosNL","colab_type":"code","colab":{}},"source":["# CIS 545 Hidden Test 1.4.3 - please do not modify or delete this cell!\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"VClkM-9BKI84","nbgrader":{"cell_type":"markdown","checksum":"ded9460c8b1a046b90326da3f3dc2b26","grade":false,"grade_id":"cell-3002547b83f8e405","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["# Step 2: Compare Evaluation Orders\n","\n","This last section relates to our discussions in lecture about computation efficiency with big data."]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"3cdd63a24299f9cb836524122a955f6b","grade":false,"grade_id":"cell-3efe42cac0356604","locked":true,"schema_version":3,"solution":false,"task":false},"id":"1AHO6W3rosNO","colab_type":"text"},"source":["## Step 2.0: Load custom functions\n","\n","Let's look at some computation and optimization tasks.  We'll start with the code from our lecture notebooks, which does joins between dataframes."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3NnnYP9pKMp1","colab":{}},"source":["# Join using nested loops\n","def merge(S,T,l_on,r_on):\n","    ret = pd.DataFrame()\n","    count = 0\n","    S_ = S.reset_index().drop(columns=['index'])\n","    T_ = T.reset_index().drop(columns=['index'])\n","    for s_index in range(0, len(S)):\n","        for t_index in range(0, len(T)):\n","            count = count + 1\n","            if S_.loc[s_index, l_on] == T_.loc[t_index, r_on]:\n","                ret = ret.append(S_.loc[s_index].append(T_.loc[t_index].drop(labels=r_on)), ignore_index=True)\n","\n","    print('Merge compared %d tuples'%count)\n","    return ret\n","  \n","# Join using a *map*, which is a kind of in-memory index\n","# from keys to (single) values\n","def merge_map(S,T,l_on,r_on):\n","    ret = pd.DataFrame()\n","    T_map = {}\n","    count = 0\n","    # Take each value in the r_on field, and\n","    # make a map entry for it\n","    T_ = T.reset_index().drop(columns=['index'])\n","    for t_index in range(0, len(T)):\n","        # Make sure we aren't overwriting an entry!\n","        assert (T_.loc[t_index,r_on] not in T_map)\n","        T_map[T_.loc[t_index,r_on]] = T_.loc[t_index]\n","        count = count + 1\n","\n","    # Now find matches\n","    S_ = S.reset_index().drop(columns=['index'])\n","    for s_index in range(0, len(S)):\n","        count = count + 1\n","        if S_.loc[s_index, l_on] in T_map:\n","                ret = ret.append(S_.loc[s_index].append(T_map[S_.loc[s_index, l_on]].drop(labels=r_on)), ignore_index=True)\n","\n","    print('Merge compared %d tuples'%count)\n","    return ret"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","deletable":false,"editable":false,"id":"OEgL47PKa-4-","nbgrader":{"cell_type":"markdown","checksum":"238fed9d183a3a48dc274222385fb871","grade":false,"grade_id":"cell-284837d450db82b2","locked":true,"schema_version":3,"solution":false,"task":false}},"source":["## Step 2.1: Find an optimal order of evaluation.\n","\n","Reimplement `recommend_jobs` using the above `merge` or `merge_map` functions instead of Pandas' merge. Try to find the **most efficient** way.  You should start with the dataframes `recs_df`, `names_df`, and `last_job_df` from above. Store your results in `recs_new_df`"]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"id":"FIBUXi58a-My","nbgrader":{"cell_type":"code","checksum":"7bcb6934880abd7bc9bc6a4cec56bad4","grade":false,"grade_id":"2-1-ans","locked":false,"schema_version":3,"solution":true,"task":false},"colab":{}},"source":["# TODO: Reimplement recommend jobs using our custom merge and merge_map functions\n","\n","def recommend_jobs_new(recs_df, names_df, last_job_df):\n","    #display(recs_df)\n","    #display(last_job_df)\n","    #display(names_df)\n","    #utilizing merge\n","    '''\n","    final_person1_dataframe = merge(recs_df, last_job_df, 'person_1', 'person')\n","    final_person_2_dataframe = merge(recs_df, last_job_df, 'person_2', 'person')  \n","    recs_new_df = pd.concat([final_person1_dataframe, final_person_2_dataframe], ignore_index=True)\n","    recs_new_df = merge(recs_new_df, names_df, 'person_1', 'person')\n","    #display(recs_new_df)\n","    recs_new_df = recs_new_df[recs_new_df['person_1'] != recs_new_df['person_2']]\n","    recs_new_df = recs_new_df.drop(columns=['common_skills', 'person_1'])\n","    #display(recs_new_df)'''\n","\n","\n","    #utilizing merge_map\n","    final_person1_dataframe = merge_map(recs_df, last_job_df, 'person_1', 'person')\n","    #display(final_person1_dataframe)\n","\n","    final_person_2_dataframe = merge_map(recs_df, last_job_df, 'person_2', 'person')  \n","    #display(final_person_2_dataframe)\n","    \n","    recs_new_df = pd.concat([final_person1_dataframe, final_person_2_dataframe], ignore_index=True)\n","    #display(recs_new_df)\n","\n","    recs_new_df = merge_map(recs_new_df, names_df, 'person_1', 'person')\n","    display(recs_new_df)\n","    #recs_new_df_2 = merge_map(recs_new_df, names_df, 'person_2', 'person')\n","    #recs_new_df = pd.concat([final_person1_dataframe, final_person_2_dataframe], ignore_index=True)\n","    #recs_new_df = recs_new_df.rename(columns={'_id_x':'person_1', '_id_y':'person_2'})\n","    recs_new_df = recs_new_df[recs_new_df['person_1'] != recs_new_df['person_2']]\n","    recs_new_df = recs_new_df.drop(columns=['common_skills', 'person_1'])\n","    display(recs_new_df)\n","    \n","    return recs_new_df\n","    # YOUR CODE HERE\n","    #raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","deletable":false,"editable":false,"id":"aHKleD_beO-R","nbgrader":{"cell_type":"code","checksum":"7650a2937ca3f86e70c62f6f92d57a53","grade":true,"grade_id":"2-1-san","locked":true,"points":2,"schema_version":3,"solution":false,"task":false},"colab":{}},"source":["# CIS 545 Sanity Check 2.1 - please do not modify or delete this cell!\n","\n","%%time\n","\n","recs_new_df = recommend_jobs_new(recs_df, names_df, last_job_df)\n","\n","if(len(recs_new_df.columns) != 5):\n","    raise AssertionError('Wrong number of columns in recs_new_df')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"cell_type":"markdown","checksum":"afff0a1143ee92daa1e08ab8e78d3e80","grade":false,"grade_id":"cell-81f2cb0677708414","locked":true,"schema_version":3,"solution":false,"task":false},"id":"BT6vJ9DXosNV","colab_type":"text"},"source":["# Step 3: Submitting Your Homework\n","\n","1. When you are done, select Edit at the top of the window, **under the filename, not the one that may appear above it**. Then, select Clear all outputs. Please do this just before turning is your homework because it reduces the size of your file.\n","\n","\n","2. In the same menu **under the filename**, select File and then Download .ipynb. It is very important that you do not change the file name of this downloaded notebook. Make sure that something like (1) did not get added to the filename and also that you did not download the .py version. Our autograder can only handle .ipynb files with the correct file name.\n","\n","3. Compress the ipynb file into a Zip file **hw2.zip**.\n","\n","4. Go to the [submission site](http://submit.dataanalytics.education), and click on the Google icon.  Log in using your Google@SEAS (if at all possible!) or (if you arent an Engineering student) GMail account.  \n","\n","5. Click on the **Courses** icon at the top, then select **CIS 545** and **Save**. Select **cis545-2019c-hw2** and upload **hw2.zip**.\n","\n","6. You should see a message on the submission site notifying you about whether your submission passed validation.  You may resubmit as necessary, but may have to withdraw your previous submission in OpenSubmit in order to do so.\n","\n","**If you have not already, please go to Settings and set your Student ID to your PennID (all numbers)**."]}]}